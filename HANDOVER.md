# AGENT HANDOVER - OpenClaw Telegram Bot

**Last Updated**: 2026-02-17  
**Current Status**: ‚úÖ **WORKING** - Bot responds via NVIDIA API (slow but functional)  
**Priority**: MEDIUM - Now building CLI Router

---

## üéâ Current Status

**‚úÖ Telegram Bot WORKING!**
- Bot: `@assistant_clauze_bot`
- Provider: NVIDIA API (`moonshotai/kimi-k2.5`)
- Status: Responding to messages (slow ~10-20s response time)
- API Key: `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`

**‚úÖ Completed Fixes:**
1. Disk space freed (7GB)
2. Bot token configured
3. NVIDIA API provider configured
4. Gateway running with correct model

---

## üîß Current Task: Build CLI Router

**Goal**: Create a unified OpenAI-compatible API router that wraps multiple CLI tools:
- OpenCode CLI
- Kilocode CLI  
- Claude Code CLI

**Repository**: https://github.com/IsleOf/wraprouter

### Router Features Needed:
1. ‚úÖ OpenAI-compatible `/v1/chat/completions` endpoint
2. ‚úÖ Model multiplexing (route to correct backend)
3. ‚è≥ Support for multiple CLI backends
4. ‚è≥ Error handling & retries
5. ‚è≥ Request/response logging
6. ‚è≥ Configuration file support

### Router Architecture:
```
OpenClaw ‚Üí CLI Router (port 4097) ‚Üí CLI Tool (OpenCode/Kilocode/Claude)
                ‚Üì
         Standard OpenAI API format
```

---

## üìã Configuration

### OpenClaw Config Location:
`/home/ubuntu/.openclaw/openclaw.json`

### Current Working Config:
```json
{
  "models": {
    "providers": {
      "nvidia": {
        "baseUrl": "https://integrate.api.nvidia.com/v1",
        "apiKey": "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",
        "api": "openai-completions",
        "models": [
          {
            "id": "moonshotai/kimi-k2.5",
            "name": "Kimi K2.5 (NVIDIA)"
          }
        ]
      }
    }
  },
  "agents": {
    "defaults": {
      "model": {
        "primary": "nvidia/moonshotai/kimi-k2.5"
      }
    }
  }
}
```

---

## üõ†Ô∏è Development Commands

### Check Bot Status:
```bash
export PATH=$HOME/.npm-global/bin:$PATH
openclaw gateway status
```

### View Logs:
```bash
tail -f /tmp/openclaw-1000/openclaw-2026-02-17.log | grep -E "telegram|nvidia|agent"
```

### Test NVIDIA API:
```bash
curl -s https://integrate.api.nvidia.com/v1/models \
  -H "Authorization: Bearer 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"
```

### SSH to VPS:
```bash
ssh -i ~/.ssh/tailscale_key ubuntu@100.93.10.110
```

---

## üìù CLI Router Specification

The router should:

1. **Listen on port 4097** (or configurable)
2. **Accept OpenAI-compatible requests**:
   - POST `/v1/chat/completions`
   - GET `/v1/models`
3. **Route to correct backend** based on model ID:
   - `opencode/*` ‚Üí OpenCode CLI
   - `kilocode/*` ‚Üí Kilocode CLI
   - `claude/*` ‚Üí Claude Code CLI
4. **Convert responses** to OpenAI format:
   - Content as STRING (not array) for openai-completions API
5. **Handle errors gracefully**

### Example Request Flow:
```
OpenClaw sends:
POST /v1/chat/completions
{
  "model": "opencode/kimi-k2.5-free",
  "messages": [{"role": "user", "content": "Hello"}]
}

Router executes:
opencode run -m opencode/kimi-k2.5-free "Hello"

Router returns:
{
  "choices": [{
    "message": {
      "role": "assistant",
      "content": "Hello! How can I help?"
    }
  }]
}
```

---

## üÜò Troubleshooting

**If bot stops responding:**
1. Check gateway: `openclaw gateway status`
2. Check logs: `tail /tmp/openclaw-1000/openclaw-2026-02-17.log`
3. Check NVIDIA API: Test with curl
4. Restart gateway: `openclaw gateway restart`

**Slow responses:**
- NVIDIA API has latency (~10-20s)
- This is normal for free tier
- Consider upgrading or using local models

---

**Next Action**: Continue building CLI Router with multi-backend support
